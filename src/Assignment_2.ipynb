{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自然言語処理 課題2\n",
    "AE2 No. 4 植原 真人\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Describe the class of strings matched by the following regular expressions.\n",
    "\n",
    "- a. [a-zA-Z]+\n",
    "- b. [A-Z][a-z]*\n",
    "- c. p[aeiou]{,2}t\n",
    "- d. \\d+(\\.\\d+)?\n",
    "- e. ([^aeiou][aeiou][^aeiou])*\n",
    "- f. \\w+|[^\\w\\s]+\n",
    "\n",
    "\n",
    "Test your answers using nltk.re_show()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://murashun.jp/article/programming/regular-expression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "\n",
    "regexp = [\n",
    "    r\"[a-zA-Z]+\",\n",
    "    r\"[A-Z][a-z]*\", \n",
    "    r\"p[aeiou]{,2}t\",\n",
    "    r\"\\d+(\\.\\d+)?\", \n",
    "    r\"([^aeiou][aeiou][^aeiou])*\", \n",
    "    r\"\\w+|[^\\w\\s]+\"\n",
    "]\n",
    "\n",
    "teststr = [\n",
    "    \"ab AB A a zAz 2abCd A/Bcd 234\", \n",
    "    \"ab AB A a zAz 2abCd A/Bcd 234 Abcdefghi\",\n",
    "    \"pt pet peat peiot poem eat\",\n",
    "    \"1 11.1 21. .33 3.14159\",\n",
    "    \".ar tat pop boo juckan\",\n",
    "    \"asjdkl !? !a!a hello, world!\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. [a-zA-Z]+\n",
    "アルファベットの大文字あるいは小文字が1回以上繰り返す文字列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ab} {AB} {A} {a} {zAz} 2{abCd} {A}/{Bcd} 234\n"
     ]
    }
   ],
   "source": [
    "nltk.re_show(regexp[0], teststr[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. [A-Z][a-z]*\n",
    "アルファベットの大文字1文字の後に小文字が0回以上繰り返す文字列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ab {A}{B} {A} a z{Az} 2ab{Cd} {A}/{Bcd} 234 {Abcdefghi}\n"
     ]
    }
   ],
   "source": [
    "nltk.re_show(regexp[1], teststr[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. p[aeiou]{,2}t\n",
    "pで始まり，間にaeiouの中から最大で２文字入り，最後がtで終わる文字列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{pt} {pet} {peat} peiot poem eat\n"
     ]
    }
   ],
   "source": [
    "nltk.re_show(regexp[2], teststr[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. \\d+(\\.\\d+)?\n",
    "半角数字１文字のみあるいはそのあとにピリオドと１文字以上の数字が続く文字列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1} {11.1} {21}. .{33} {3.14159}\n"
     ]
    }
   ],
   "source": [
    "nltk.re_show(regexp[3], teststr[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e. ([^aeiou][aeiou][^aeiou])*\n",
    "aeiou以外の文字１文字のあとにaeiouから１文字が続き，その後にaeiou以外の文字が続く組み合わせを0回以上繰り返した文字列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{.ar}{} {tat}{} {pop}{} {}b{}o{}o{} {juckan}{}\n"
     ]
    }
   ],
   "source": [
    "nltk.re_show(regexp[4], teststr[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f. \\w+|[^\\w\\s]+]\n",
    "英数字が1文字以上連続した文字列，あるいは英数字と空白文字以外の文字が１文字以上の連続した文字列のどちらか"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{asjdkl} {!?} {!}{a}{!}{a} {hello}{,} {world}{!}\n"
     ]
    }
   ],
   "source": [
    "nltk.re_show(regexp[5], teststr[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Write a utility function that takes a URL as its argument, and returns the contents of the URL, with all HTML markup removed. Use from urllib import request and then request.urlopen('http://nltk.org/').read().decode('utf8') to access the contents of the URL.\n",
    "beautiful soupを用いる．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Natural', 'Language', 'Toolkit', '—', 'NLTK', '3.6.2', 'documentation', 'NLTK', '3.6.2', 'documentation', 'next', '|', 'modules', '|', 'index', 'Natural', 'Language', 'Toolkit¶', 'NLTK', 'is', 'a', 'leading', 'platform', 'for', 'building', 'Python', 'programs', 'to', 'work', 'with', 'human', 'language', 'data', '.', 'It', 'provides', 'easy-to-use', 'interfaces', 'to', 'over', '50', 'corpora', 'and', 'lexical', 'resources', 'such', 'as', 'WordNet', ',', 'along', 'with', 'a', 'suite', 'of', 'text', 'processing', 'libraries', 'for', 'classification', ',', 'tokenization', ',', 'stemming', ',', 'tagging', ',', 'parsing', ',', 'and', 'semantic', 'reasoning', ',', 'wrappers', 'for', 'industrial-strength', 'NLP', 'libraries', ',', 'and', 'an', 'active', 'discussion', 'forum', '.', 'Thanks', 'to', 'a', 'hands-on', 'guide', 'introducing', 'programming', 'fundamentals', 'alongside', 'topics', 'in', 'computational', 'linguistics', ',', 'plus', 'comprehensive', 'API', 'documentation', ',', 'NLTK', 'is', 'suitable', 'for', 'linguists', ',', 'engineers', ',', 'students', ',', 'educators', ',', 'researchers', ',', 'and', 'industry', 'users', 'alike', '.', 'NLTK', 'is', 'available', 'for', 'Windows', ',', 'Mac', 'OS', 'X', ',', 'and', 'Linux', '.', 'Best', 'of', 'all', ',', 'NLTK', 'is', 'a', 'free', ',', 'open', 'source', ',', 'community-driven', 'project', '.', 'NLTK', 'has', 'been', 'called', '“', 'a', 'wonderful', 'tool', 'for', 'teaching', ',', 'and', 'working', 'in', ',', 'computational', 'linguistics', 'using', 'Python', ',', '”', 'and', '“', 'an', 'amazing', 'library', 'to', 'play', 'with', 'natural', 'language.', '”', 'Natural', 'Language', 'Processing', 'with', 'Python', 'provides', 'a', 'practical', 'introduction', 'to', 'programming', 'for', 'language', 'processing', '.', 'Written', 'by', 'the', 'creators', 'of', 'NLTK', ',', 'it', 'guides', 'the', 'reader', 'through', 'the', 'fundamentals', 'of', 'writing', 'Python', 'programs', ',', 'working', 'with', 'corpora', ',', 'categorizing', 'text', ',', 'analyzing', 'linguistic', 'structure', ',', 'and', 'more', '.', 'The', 'online', 'version', 'of', 'the', 'book', 'has', 'been', 'been', 'updated', 'for', 'Python', '3', 'and', 'NLTK', '3', '.', '(', 'The', 'original', 'Python', '2', 'version', 'is', 'still', 'available', 'at', 'http', ':', '//nltk.org/book_1ed', '.', ')', 'Some', 'simple', 'things', 'you', 'can', 'do', 'with', 'NLTK¶', 'Tokenize', 'and', 'tag', 'some', 'text', ':', '>', '>', '>', 'import', 'nltk', '>', '>', '>', 'sentence', '=', '``', \"''\", \"''\", 'At', 'eight', \"o'clock\", 'on', 'Thursday', 'morning', '...', 'Arthur', 'did', \"n't\", 'feel', 'very', 'good', '.', \"''\", \"''\", \"''\", '>', '>', '>', 'tokens', '=', 'nltk.word_tokenize', '(', 'sentence', ')', '>', '>', '>', 'tokens', '[', \"'At\", \"'\", ',', \"'eight\", \"'\", ',', '``', \"o'clock\", \"''\", ',', \"'on\", \"'\", ',', \"'Thursday\", \"'\", ',', \"'morning\", \"'\", ',', \"'Arthur\", \"'\", ',', \"'did\", \"'\", ',', '``', \"n't\", \"''\", ',', \"'feel\", \"'\", ',', \"'very\", \"'\", ',', \"'good\", \"'\", ',', \"'\", '.', \"'\", ']', '>', '>', '>', 'tagged', '=', 'nltk.pos_tag', '(', 'tokens', ')', '>', '>', '>', 'tagged', '[', '0:6', ']', '[', '(', \"'At\", \"'\", ',', \"'IN\", \"'\", ')', ',', '(', \"'eight\", \"'\", ',', \"'CD\", \"'\", ')', ',', '(', '``', \"o'clock\", \"''\", ',', \"'JJ\", \"'\", ')', ',', '(', \"'on\", \"'\", ',', \"'IN\", \"'\", ')', ',', '(', \"'Thursday\", \"'\", ',', \"'NNP\", \"'\", ')', ',', '(', \"'morning\", \"'\", ',', \"'NN\", \"'\", ')', ']', 'Identify', 'named', 'entities', ':', '>', '>', '>', 'entities', '=', 'nltk.chunk.ne_chunk', '(', 'tagged', ')', '>', '>', '>', 'entities', 'Tree', '(', \"'S\", \"'\", ',', '[', '(', \"'At\", \"'\", ',', \"'IN\", \"'\", ')', ',', '(', \"'eight\", \"'\", ',', \"'CD\", \"'\", ')', ',', '(', '``', \"o'clock\", \"''\", ',', \"'JJ\", \"'\", ')', ',', '(', \"'on\", \"'\", ',', \"'IN\", \"'\", ')', ',', '(', \"'Thursday\", \"'\", ',', \"'NNP\", \"'\", ')', ',', '(', \"'morning\", \"'\", ',', \"'NN\", \"'\", ')', ',', 'Tree', '(', \"'PERSON\", \"'\", ',', '[', '(', \"'Arthur\", \"'\", ',', \"'NNP\", \"'\", ')', ']', ')', ',', '(', \"'did\", \"'\", ',', \"'VBD\", \"'\", ')', ',', '(', '``', \"n't\", \"''\", ',', \"'RB\", \"'\", ')', ',', '(', \"'feel\", \"'\", ',', \"'VB\", \"'\", ')', ',', '(', \"'very\", \"'\", ',', \"'RB\", \"'\", ')', ',', '(', \"'good\", \"'\", ',', \"'JJ\", \"'\", ')', ',', '(', \"'\", '.', \"'\", ',', \"'\", '.', \"'\", ')', ']', ')', 'Display', 'a', 'parse', 'tree', ':', '>', '>', '>', 'from', 'nltk.corpus', 'import', 'treebank', '>', '>', '>', 't', '=', 'treebank.parsed_sents', '(', \"'wsj_0001.mrg\", \"'\", ')', '[', '0', ']', '>', '>', '>', 't.draw', '(', ')', 'NB', '.', 'If', 'you', 'publish', 'work', 'that', 'uses', 'NLTK', ',', 'please', 'cite', 'the', 'NLTK', 'book', 'as', 'follows', ':', 'Bird', ',', 'Steven', ',', 'Edward', 'Loper', 'and', 'Ewan', 'Klein', '(', '2009', ')', ',', 'Natural', 'Language', 'Processing', 'with', 'Python', '.', 'O', '’', 'Reilly', 'Media', 'Inc.', 'Next', 'Steps¶', 'sign', 'up', 'for', 'release', 'announcements', 'join', 'in', 'the', 'discussion', 'Contents¶', 'NLTK', 'News', 'Installing', 'NLTK', 'Installing', 'NLTK', 'Data', 'Contribute', 'to', 'NLTK', 'FAQ', 'Wiki', 'API', 'HOWTO', 'Index', 'Module', 'Index', 'Search', 'Page', 'Table', 'of', 'Contents', 'NLTK', 'News', 'Installing', 'NLTK', 'Installing', 'NLTK', 'Data', 'Contribute', 'to', 'NLTK', 'FAQ', 'Wiki', 'API', 'HOWTO', 'Search', 'next', '|', 'modules', '|', 'index', 'Show', 'Source', '©', 'Copyright', '2021', ',', 'NLTK', 'Project', '.', 'Last', 'updated', 'on', 'Apr', '20', ',', '2021', '.', 'Created', 'using', 'Sphinx', '3.5.2', '.']\n"
     ]
    }
   ],
   "source": [
    "from urllib import request\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk import word_tokenize\n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "\n",
    "\n",
    "def get_rawtext(url):\n",
    "    html = request.urlopen(url).read().decode('utf8')\n",
    "    raw = BeautifulSoup(html, 'html.parser').get_text()\n",
    "    tokens = word_tokenize(raw)\n",
    "\n",
    "    return tokens\n",
    "\n",
    "url = 'http://nltk.org/'\n",
    "text = get_rawtext(url)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 日本語で100文字程度の自己紹介文を作成し，UTF8でテキストファイルに保存せよ．そのファイルをJanomeもしくはMeCabで分かち書きで表示するプログラムを書き，結果も表示せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "こんにちは\t感動詞,*,*,*,*,*,こんにちは,コンニチハ,コンニチワ\n",
      "．\t記号,句点,*,*,*,*,．,．,．\n",
      "うえ\t名詞,一般,*,*,*,*,うえ,ウエ,ウエ\n",
      "はらま\t動詞,自立,*,*,五段・マ行,未然形,はらむ,ハラマ,ハラマ\n",
      "さ\t名詞,接尾,特殊,*,*,*,さ,サ,サ\n",
      "と\t助詞,並立助詞,*,*,*,*,と,ト,ト\n",
      "です\t助動詞,*,*,*,特殊・デス,基本形,です,デス,デス\n",
      "．\t記号,句点,*,*,*,*,．,．,．\n",
      "趣味\t名詞,一般,*,*,*,*,趣味,シュミ,シュミ\n",
      "は\t助詞,係助詞,*,*,*,*,は,ハ,ワ\n",
      "旅行\t名詞,サ変接続,*,*,*,*,旅行,リョコウ,リョコー\n",
      "，\t記号,読点,*,*,*,*,，,，,，\n",
      "スノーボード\t名詞,一般,*,*,*,*,スノーボード,スノーボード,スノーボード\n",
      "，\t記号,読点,*,*,*,*,，,，,，\n",
      "映画\t名詞,一般,*,*,*,*,映画,エイガ,エイガ\n",
      "鑑賞\t名詞,サ変接続,*,*,*,*,鑑賞,カンショウ,カンショー\n",
      "です\t助動詞,*,*,*,特殊・デス,基本形,です,デス,デス\n",
      "．\t記号,句点,*,*,*,*,．,．,．\n",
      "いま\t名詞,副詞可能,*,*,*,*,いま,イマ,イマ\n",
      "は\t助詞,係助詞,*,*,*,*,は,ハ,ワ\n",
      "五島列島\t名詞,固有名詞,一般,*,*,*,五島列島,ゴトウレットウ,ゴトーレットー\n",
      "と\t助詞,並立助詞,*,*,*,*,と,ト,ト\n",
      "知床\t名詞,固有名詞,地域,一般,*,*,知床,シレトコ,シレトコ\n",
      "に\t助詞,格助詞,一般,*,*,*,に,ニ,ニ\n",
      "行っ\t動詞,自立,*,*,五段・カ行促音便,連用タ接続,行く,イッ,イッ\n",
      "て\t助詞,接続助詞,*,*,*,*,て,テ,テ\n",
      "み\t動詞,非自立,*,*,一段,連用形,みる,ミ,ミ\n",
      "たい\t助動詞,*,*,*,特殊・タイ,基本形,たい,タイ,タイ\n",
      "と\t助詞,格助詞,引用,*,*,*,と,ト,ト\n",
      "おもっ\t動詞,自立,*,*,五段・ワ行促音便,連用タ接続,おもう,オモッ,オモッ\n",
      "て\t助詞,接続助詞,*,*,*,*,て,テ,テ\n",
      "い\t動詞,非自立,*,*,一段,連用形,いる,イ,イ\n",
      "ます\t助動詞,*,*,*,特殊・マス,基本形,ます,マス,マス\n",
      "．\t記号,句点,*,*,*,*,．,．,．\n",
      "今年\t名詞,副詞可能,*,*,*,*,今年,コトシ,コトシ\n",
      "の\t助詞,連体化,*,*,*,*,の,ノ,ノ\n",
      "冬\t名詞,一般,*,*,*,*,冬,フユ,フユ\n",
      "に\t助詞,格助詞,一般,*,*,*,に,ニ,ニ\n",
      "は\t助詞,係助詞,*,*,*,*,は,ハ,ワ\n",
      "北海道\t名詞,固有名詞,地域,一般,*,*,北海道,ホッカイドウ,ホッカイドー\n",
      "に\t助詞,格助詞,一般,*,*,*,に,ニ,ニ\n",
      "行っ\t動詞,自立,*,*,五段・カ行促音便,連用タ接続,行く,イッ,イッ\n",
      "て\t助詞,接続助詞,*,*,*,*,て,テ,テ\n",
      "スノーボード\t名詞,一般,*,*,*,*,スノーボード,スノーボード,スノーボード\n",
      "を\t助詞,格助詞,一般,*,*,*,を,ヲ,ヲ\n",
      "し\t動詞,自立,*,*,サ変・スル,連用形,する,シ,シ\n",
      "たい\t助動詞,*,*,*,特殊・タイ,基本形,たい,タイ,タイ\n",
      "です\t助動詞,*,*,*,特殊・デス,基本形,です,デス,デス\n",
      "．\t記号,句点,*,*,*,*,．,．,．\n"
     ]
    }
   ],
   "source": [
    "from janome.tokenizer import Tokenizer\n",
    "t = Tokenizer()\n",
    "path = 'text.txt'\n",
    "si = \"こんにちは．うえはらまさとです．趣味は旅行，スノーボード，映画鑑賞です．いまは五島列島と知床に行ってみたいとおもっています．今年の冬には北海道に行ってスノーボードをしたいです．\"\n",
    "\n",
    "# 書き込み\n",
    "with open(path, mode='w', encoding='utf-8') as f:\n",
    "    f.write(si)\n",
    "# 読み込み\n",
    "with open(path, encoding='utf-8') as f:\n",
    "    selfintro = f.read()\n",
    "\n",
    "for token in t.tokenize(selfintro):\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4cd7ab41f5fca4b9b44701077e38c5ffd31fe66a6cab21e0214b68d958d0e462"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('local')",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}