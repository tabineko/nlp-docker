{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python394jvsc74a57bd04cd7ab41f5fca4b9b44701077e38c5ffd31fe66a6cab21e0214b68d958d0e462",
   "display_name": "Python 3.9.4 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['[', 'Emma', 'by', 'Jane', 'Austen', '1816', ']', ...]"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "emma = nltk.corpus.gutenberg.words('austen-emma.txt')\n",
    "emma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "5 25 26 austen-emma.txt\n",
      "5 26 17 austen-persuasion.txt\n",
      "5 28 22 austen-sense.txt\n",
      "4 34 79 bible-kjv.txt\n",
      "5 19 5 blake-poems.txt\n",
      "4 19 14 bryant-stories.txt\n",
      "4 18 12 burgess-busterbrown.txt\n",
      "4 20 13 carroll-alice.txt\n",
      "5 20 12 chesterton-ball.txt\n",
      "5 23 11 chesterton-brown.txt\n",
      "5 18 11 chesterton-thursday.txt\n",
      "4 21 25 edgeworth-parents.txt\n",
      "5 26 15 melville-moby_dick.txt\n",
      "5 52 11 milton-paradise.txt\n",
      "4 12 9 shakespeare-caesar.txt\n",
      "4 12 8 shakespeare-hamlet.txt\n",
      "4 12 7 shakespeare-macbeth.txt\n",
      "5 36 12 whitman-leaves.txt\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import gutenberg\n",
    "\n",
    "for fileid in gutenberg.fileids():\n",
    "    num_chars = len(gutenberg.raw(fileid))\n",
    "    num_words = len(gutenberg.words(fileid))\n",
    "    num_sents = len(gutenberg.sents(fileid))\n",
    "    num_vocab = len(set(w.lower() for w in gutenberg.words(fileid)))\n",
    "    print(round(num_chars/num_words), round(num_words/num_sents), round(num_words/num_vocab), fileid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[['[', 'The', 'Tragedie', 'of', 'Macbeth', 'by', 'William', 'Shakespeare', '1603', ']'], ['Actus', 'Primus', '.'], ...]\n['Double', ',', 'double', ',', 'toile', 'and', 'trouble', ';', 'Fire', 'burne', ',', 'and', 'Cauldron', 'bubble']\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[['Doubtfull',\n",
       "  'it',\n",
       "  'stood',\n",
       "  ',',\n",
       "  'As',\n",
       "  'two',\n",
       "  'spent',\n",
       "  'Swimmers',\n",
       "  ',',\n",
       "  'that',\n",
       "  'doe',\n",
       "  'cling',\n",
       "  'together',\n",
       "  ',',\n",
       "  'And',\n",
       "  'choake',\n",
       "  'their',\n",
       "  'Art',\n",
       "  ':',\n",
       "  'The',\n",
       "  'mercilesse',\n",
       "  'Macdonwald',\n",
       "  '(',\n",
       "  'Worthie',\n",
       "  'to',\n",
       "  'be',\n",
       "  'a',\n",
       "  'Rebell',\n",
       "  ',',\n",
       "  'for',\n",
       "  'to',\n",
       "  'that',\n",
       "  'The',\n",
       "  'multiplying',\n",
       "  'Villanies',\n",
       "  'of',\n",
       "  'Nature',\n",
       "  'Doe',\n",
       "  'swarme',\n",
       "  'vpon',\n",
       "  'him',\n",
       "  ')',\n",
       "  'from',\n",
       "  'the',\n",
       "  'Westerne',\n",
       "  'Isles',\n",
       "  'Of',\n",
       "  'Kernes',\n",
       "  'and',\n",
       "  'Gallowgrosses',\n",
       "  'is',\n",
       "  'supply',\n",
       "  \"'\",\n",
       "  'd',\n",
       "  ',',\n",
       "  'And',\n",
       "  'Fortune',\n",
       "  'on',\n",
       "  'his',\n",
       "  'damned',\n",
       "  'Quarry',\n",
       "  'smiling',\n",
       "  ',',\n",
       "  'Shew',\n",
       "  \"'\",\n",
       "  'd',\n",
       "  'like',\n",
       "  'a',\n",
       "  'Rebells',\n",
       "  'Whore',\n",
       "  ':',\n",
       "  'but',\n",
       "  'all',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'too',\n",
       "  'weake',\n",
       "  ':',\n",
       "  'For',\n",
       "  'braue',\n",
       "  'Macbeth',\n",
       "  '(',\n",
       "  'well',\n",
       "  'hee',\n",
       "  'deserues',\n",
       "  'that',\n",
       "  'Name',\n",
       "  ')',\n",
       "  'Disdayning',\n",
       "  'Fortune',\n",
       "  ',',\n",
       "  'with',\n",
       "  'his',\n",
       "  'brandisht',\n",
       "  'Steele',\n",
       "  ',',\n",
       "  'Which',\n",
       "  'smoak',\n",
       "  \"'\",\n",
       "  'd',\n",
       "  'with',\n",
       "  'bloody',\n",
       "  'execution',\n",
       "  '(',\n",
       "  'Like',\n",
       "  'Valours',\n",
       "  'Minion',\n",
       "  ')',\n",
       "  'caru',\n",
       "  \"'\",\n",
       "  'd',\n",
       "  'out',\n",
       "  'his',\n",
       "  'passage',\n",
       "  ',',\n",
       "  'Till',\n",
       "  'hee',\n",
       "  'fac',\n",
       "  \"'\",\n",
       "  'd',\n",
       "  'the',\n",
       "  'Slaue',\n",
       "  ':',\n",
       "  'Which',\n",
       "  'neu',\n",
       "  \"'\",\n",
       "  'r',\n",
       "  'shooke',\n",
       "  'hands',\n",
       "  ',',\n",
       "  'nor',\n",
       "  'bad',\n",
       "  'farwell',\n",
       "  'to',\n",
       "  'him',\n",
       "  ',',\n",
       "  'Till',\n",
       "  'he',\n",
       "  'vnseam',\n",
       "  \"'\",\n",
       "  'd',\n",
       "  'him',\n",
       "  'from',\n",
       "  'the',\n",
       "  'Naue',\n",
       "  'toth',\n",
       "  \"'\",\n",
       "  'Chops',\n",
       "  ',',\n",
       "  'And',\n",
       "  'fix',\n",
       "  \"'\",\n",
       "  'd',\n",
       "  'his',\n",
       "  'Head',\n",
       "  'vpon',\n",
       "  'our',\n",
       "  'Battlements']]"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "macbeth_sentences = gutenberg.sents('shakespeare-macbeth.txt')\n",
    "print(macbeth_sentences)\n",
    "print(macbeth_sentences[1116])\n",
    "longest_len = max(len(s) for s in macbeth_sentences)\n",
    "[s for s in macbeth_sentences if len(s) == longest_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                 what  when where   who   why \n           news    76   128    58   268     9 \n       religion    64    53    20   100    14 \n        hobbies    78   119    72   103    10 \nscience_fiction    27    21    10    13     4 \n        romance   121   126    54    89    34 \n          humor    36    52    15    48     9 \n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "\n",
    "genres = ['news', 'religion', 'hobbies', 'science_fiction', 'romance', 'humor']\n",
    "whwords = ['what', 'when', 'where', 'who', 'why']\n",
    "cfd = nltk.ConditionalFreqDist((genre, word) for genre in genres for word in brown.words(categories=genre))\n",
    "cfd.tabulate(conditions=genres, samples=whwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                 what  when where   who   why \n           news    95   169    59   268    14 \n       religion    86    68    21   102    20 \n        hobbies   108   164    77   104    17 \nscience_fiction    41    28    15    13     8 \n        romance   171   163    58    95    62 \n          humor    46    62    16    49    13 \n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "genres = ['news', 'religion', 'hobbies', 'science_fiction', 'romance', 'humor']\n",
    "whwords = ['what', 'when', 'where', 'who', 'why']\n",
    "cfd = nltk.ConditionalFreqDist((genre, word.lower()) for genre in genres for word in brown.words(categories=genre))\n",
    "\n",
    "cfd.tabulate(conditions=genres, samples=whwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                  can could   may might  must  will \n           news    94    87    93    38    53   389 \n       religion    84    59    79    12    54    72 \n        hobbies   276    59   143    22    84   269 \nscience_fiction    16    49     4    12     8    17 \n        romance    79   195    11    51    46    49 \n          humor    17    33     8     8     9    13 \n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "\n",
    "genres = ['news', 'religion', 'hobbies', 'science_fiction', 'romance', 'humor']\n",
    "whwords = ['can', 'could', 'may', 'might', 'must', 'will']\n",
    "cfd = nltk.ConditionalFreqDist((genre, word.lower()) for genre in genres for word in brown.words(categories=genre))\n",
    "cfd.tabulate(conditions=genres, samples=whwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[('.', 4057),\n (',', 3488),\n ('the', 3370),\n ('and', 1622),\n ('a', 1354),\n ('of', 1322),\n ('to', 1309),\n ('``', 998),\n (\"''\", 995),\n ('was', 914),\n ('in', 847),\n ('his', 776),\n ('he', 761),\n ('I', 652),\n ('had', 591),\n ('He', 522),\n ('?', 518),\n ('that', 494),\n ('it', 492),\n ('on', 460)]\n[('the', 9726),\n (',', 9166),\n ('.', 6397),\n ('of', 6289),\n ('and', 4282),\n ('to', 4084),\n ('a', 3308),\n ('in', 3089),\n ('that', 1896),\n ('is', 1799),\n ('was', 1467),\n ('his', 1342),\n ('``', 1320),\n (\"''\", 1309),\n ('for', 1191),\n ('he', 1174),\n ('as', 1160),\n ('with', 1060),\n ('it', 1059),\n ('The', 1030)]\n[('the', 3508),\n (',', 2766),\n ('.', 2481),\n ('of', 1976),\n ('to', 1554),\n ('and', 1302),\n ('a', 1095),\n ('in', 1001),\n ('is', 744),\n ('that', 578),\n ('for', 509),\n ('The', 453),\n ('be', 421),\n ('``', 396),\n ('it', 386),\n (\"''\", 382),\n ('as', 356),\n ('on', 336),\n ('with', 316),\n ('was', 308)]\n[(',', 3654),\n ('.', 3639),\n ('the', 3423),\n ('and', 1696),\n ('to', 1489),\n ('of', 1419),\n ('a', 1281),\n ('was', 1082),\n ('in', 916),\n ('he', 813),\n ('his', 735),\n ('had', 726),\n ('``', 703),\n (\"''\", 698),\n ('?', 564),\n ('that', 530),\n ('I', 511),\n ('He', 495),\n ('with', 468),\n ('it', 458)]\n[('the', 4143),\n (',', 3405),\n ('of', 3031),\n ('.', 2493),\n ('and', 1923),\n ('to', 1829),\n ('in', 1319),\n ('a', 867),\n ('for', 806),\n ('is', 649),\n ('be', 600),\n ('that', 489),\n ('The', 478),\n ('as', 453),\n (';', 444),\n ('by', 428),\n ('are', 415),\n ('on', 401),\n ('or', 399),\n ('with', 358)]\n[('the', 4300),\n (',', 3849),\n ('.', 3453),\n ('of', 2390),\n ('and', 2144),\n ('to', 1797),\n ('a', 1737),\n ('in', 1427),\n ('is', 959),\n ('for', 776),\n ('with', 595),\n ('on', 515),\n ('that', 514),\n (';', 512),\n ('are', 508),\n ('be', 508),\n ('it', 476),\n ('The', 458),\n ('or', 457),\n ('as', 452)]\n[(',', 1331),\n ('the', 930),\n ('.', 877),\n ('of', 515),\n ('and', 512),\n ('a', 505),\n ('to', 463),\n ('``', 343),\n (\"''\", 340),\n ('in', 334),\n ('was', 274),\n ('that', 241),\n ('I', 239),\n ('it', 162),\n ('?', 152),\n ('for', 150),\n ('had', 149),\n ('he', 146),\n ('his', 137),\n ('you', 131)]\n[('the', 11079),\n (',', 8242),\n ('of', 7418),\n ('.', 6773),\n ('and', 4237),\n ('to', 3882),\n ('in', 3644),\n ('a', 3215),\n ('is', 2403),\n ('that', 1695),\n ('The', 1458),\n ('for', 1455),\n ('be', 1363),\n ('as', 1203),\n ('by', 1172),\n ('with', 1119),\n ('was', 1114),\n (';', 1000),\n ('are', 991),\n ('Af', 908)]\n[('the', 6328),\n (',', 5519),\n ('.', 4367),\n ('of', 3668),\n ('and', 2758),\n ('to', 2530),\n ('a', 2304),\n ('in', 2001),\n ('is', 1007),\n ('that', 984),\n ('was', 961),\n ('for', 882),\n ('``', 727),\n (\"''\", 717),\n ('as', 697),\n ('with', 681),\n ('The', 647),\n ('on', 594),\n ('be', 570),\n ('it', 566)]\n[('.', 3326),\n (',', 2805),\n ('the', 2573),\n ('to', 1284),\n ('and', 1215),\n ('a', 1136),\n ('of', 903),\n ('was', 820),\n ('``', 740),\n (\"''\", 738),\n ('he', 670),\n ('?', 664),\n ('in', 658),\n ('I', 583),\n ('his', 529),\n ('had', 517),\n ('it', 515),\n ('that', 494),\n ('on', 421),\n ('He', 406)]\n[('the', 5580),\n (',', 5188),\n ('.', 4030),\n ('of', 2849),\n ('and', 2146),\n ('to', 2116),\n ('a', 1993),\n ('in', 1893),\n ('for', 943),\n ('The', 806),\n ('that', 802),\n ('``', 732),\n ('is', 732),\n ('was', 717),\n (\"''\", 702),\n ('on', 657),\n ('at', 598),\n ('with', 545),\n ('be', 526),\n ('by', 497)]\n[('the', 2295),\n (',', 1913),\n ('of', 1494),\n ('.', 1382),\n ('and', 921),\n ('to', 882),\n ('in', 724),\n ('a', 655),\n ('is', 533),\n ('that', 475),\n (';', 308),\n ('as', 290),\n ('for', 283),\n ('``', 270),\n (\"''\", 266),\n ('it', 264),\n ('be', 243),\n ('not', 232),\n ('this', 217),\n ('with', 215)]\n[(',', 2318),\n ('the', 2048),\n ('.', 1549),\n ('of', 1299),\n ('and', 1103),\n ('a', 874),\n ('to', 706),\n ('in', 656),\n ('is', 513),\n ('``', 390),\n (\"''\", 389),\n ('that', 336),\n ('The', 322),\n ('with', 272),\n ('for', 268),\n ('as', 259),\n ('was', 227),\n (';', 210),\n ('his', 208),\n ('it', 206)]\n[(',', 3899),\n ('.', 3736),\n ('the', 2758),\n ('and', 1776),\n ('to', 1502),\n ('a', 1335),\n ('of', 1186),\n ('``', 1045),\n (\"''\", 1044),\n ('was', 993),\n ('I', 951),\n ('in', 875),\n ('he', 702),\n ('had', 692),\n ('?', 690),\n ('her', 651),\n ('that', 583),\n ('it', 573),\n ('his', 559),\n ('she', 496)]\n[(',', 791),\n ('.', 786),\n ('the', 652),\n ('of', 321),\n ('to', 305),\n ('and', 278),\n ('``', 235),\n (\"''\", 235),\n ('a', 222),\n ('was', 198),\n ('?', 158),\n ('in', 152),\n ('had', 141),\n ('he', 139),\n ('it', 129),\n ('that', 126),\n ('I', 98),\n ('not', 94),\n ('his', 93),\n ('for', 92)]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "cfd = nltk.ConditionalFreqDist((genre, word) for genre in brown.categories() for word in brown.words(categories=genre))\n",
    "for genre in brown.categories():\n",
    "    pprint(cfd[genre].most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "sent1: Call me Ishmael .\nsent2: The family of Dashwood had long been settled in Sussex .\nsent3: In the beginning God created the heaven and the earth .\nsent4: Fellow - Citizens of the Senate and of the House of Representatives :\nsent5: I have a problem with people PMing me to lol JOIN\nsent6: SCENE 1 : [ wind ] [ clop clop clop ] KING ARTHUR : Whoa there !\nsent7: Pierre Vinken , 61 years old , will join the board as a nonexecutive director Nov. 29 .\nsent8: 25 SEXY MALE , seeks attrac older single lady , for discreet encounters .\nsent9: THE suburb of Saffron Park lay on the sunset side of London , as red and ragged as a cloud of sunset .\n"
     ]
    }
   ],
   "source": [
    "sents()\n",
    "# list(nltk.bigrams(text3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'ConditionalFreqDist' object has no attribute 'num_vocab'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-4c04e411bc12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcfd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'ConditionalFreqDist' object has no attribute 'num_vocab'"
     ]
    }
   ],
   "source": [
    "cfd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "living creature that I am old man a space of the fish of these were "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def _word_selection(cfdist, word):\n",
    "    word_list = list(cfd[word].keys())\n",
    "    prob_word = list(cfd[word].values())\n",
    "    \n",
    "    return np.random.choice(word_list, p=np.array(prob_word)/sum(prob_word))\n",
    "\n",
    "\n",
    "def generate_model(cfdist, word, num=15):\n",
    "    for i in range(num):\n",
    "        print(word, end=' ')\n",
    "        word = _word_selection(cfdist, word)\n",
    "\n",
    "text = nltk.corpus.genesis.words('english-kjv.txt')\n",
    "bigrams = nltk.bigrams(text)\n",
    "cfd = nltk.ConditionalFreqDist(bigrams)\n",
    "generate_model(cfd, 'living')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "7\n4\n1\n1\n2\n1\n"
     ]
    }
   ],
   "source": [
    "for freq in (cfd['living'].values()):\n",
    "    print(freq)"
   ]
  }
 ]
}